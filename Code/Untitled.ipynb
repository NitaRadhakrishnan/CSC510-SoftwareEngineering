{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analysis.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import anderson\n",
    "from tabulate import tabulate\n",
    "import commonFunctions\n",
    "       \n",
    "# FUNCTION TO FIND CORRELATION BETWEEN ALL VARIABLES IN THE DATASET     \n",
    "def correlations(data, method, columns, f):\n",
    "    correlations = data[data.columns].corr(method=method)\n",
    "    for i in range(len(columns) - 1):\n",
    "        for j in range(i + 1, len(columns)):\n",
    "            if abs(correlations[columns[i]][columns[j]]) < 0.5:\n",
    "                f.writelines(\"\\nColumns \" + columns[i] + \" and \" + columns[j] +\n",
    "                             \" have low correlation between them. The correlation value is \" +\n",
    "                             str(correlations[columns[i]][columns[j]]))\n",
    "            elif abs(correlations[columns[i]][columns[j]]) > 0.98:\n",
    "                f.writelines(\"\\nColumns \" + columns[i] + \" and \" + columns[j] +\n",
    "                             \" have very high correlation between them. The correlation value is \" +\n",
    "                             str(correlations[columns[i]][columns[j]]))\n",
    "            else:\n",
    "                f.writelines(\"\\nColumns \" + columns[i] + \" and \" + columns[j] +\n",
    "                             \" have strong correlation between them. The correlation value is \"\n",
    "                             + str(correlations[columns[i]][columns[j]]))\n",
    "    f.writelines(\n",
    "        \"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    \n",
    "#FUNCTION TO WRITE ALL EDA RESULTS TO FILE AND RETURN FILE  \n",
    "def analysis(f, data, target, columns):\n",
    "\n",
    "    # Exploratory data analysis:\n",
    "    f.writelines(\"\\nEXPLORATORY DATA ANALYSIS:\")\n",
    "    \n",
    "    # Checking for Value counts if dataset is categorical \n",
    "    for col in columns:\n",
    "        if not(data[col].dtypes=='float64' or data[col].dtypes=='int64'):\n",
    "            ValueCounts(f, data, col, columns)\n",
    "       \n",
    "    # Checking effect of categorical variables on entire dataset \n",
    "    for col in columns:\n",
    "        if not(data[col].dtypes=='float64' or data[col].dtypes=='int64'):\n",
    "            GroupBy(f, data, col, columns)\n",
    "    \n",
    "    #Checking if the data set is numerical or categorical \n",
    "    flag = commonFunctions.targetCheck(target, columns)\n",
    "    if flag != 1:\n",
    "        return flag,[],0\n",
    "    data,columns,cat_flag = commonFunctions.checkAndConvertIfCategorical(data, target)\n",
    "    if cat_flag == 0:\n",
    "        f.writelines(\"\\n      The dataset is of type - Numerical\")\n",
    "    else:\n",
    "        f.writelines(\"\\n      The dataset is of type - Categorical\")\n",
    "        \n",
    "    \n",
    "    # Details about the datset\n",
    "    dataInfo(f, data, target, columns)\n",
    "    \n",
    "    #Mean, Median and Mode\n",
    "    MeanMedianMode(f, data, target, columns)\n",
    "    \n",
    "    # Correlation\n",
    "    f.writelines(\"\\n\\nCorrelation:\\n\")\n",
    "    f.writelines(\"\\nPearson Correlation test:\")\n",
    "    correlations(data, 'pearson', columns, f)\n",
    "\n",
    "    f.writelines(\"\\n\\nSpearman's rank Correlation test:\")\n",
    "    correlations(data, 'spearman', columns, f)\n",
    "\n",
    "    f.writelines(\"\\n\\nKendall's rank Correlation test:\")\n",
    "    correlations(data, 'kendall', columns, f)\n",
    "    \n",
    "    #Normality Tests\n",
    "    Normality(f, data, target, columns)\n",
    "\n",
    "#FUNCTION TO DISPLAY INFORMATION ABOUT DATASET \n",
    "def dataInfo(f, data, target, columns):\n",
    "    # number of null values per column\n",
    "    f.writelines(\"\\n\\nNo. of nulls in the columns:\\n\")\n",
    "    f.write(str(data.isnull().sum()))\n",
    "    # Information about the data: \n",
    "    f.writelines(\"\\nInformation about the data:\")\n",
    "    f.writelines(\"\\n\\nType of the data: \"+str(type(data)))\n",
    "    f.writelines(\"\\n\\nSummary statistics of the data\\n\\n\")\n",
    "    f.writelines(str(data.describe()))\n",
    "    f.writelines(\"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "     \n",
    "\n",
    "#FUNCTION TO FIND MEAN, MEDIAN, MODE OF EVERY COLUMN\n",
    "def MeanMedianMode(f, data, target, columns):\n",
    "    # Mean, median and mode of each column:\n",
    "    f.writelines(\"\\n\\nMEAN, MEDIAN AND MODE:\")\n",
    "    for col in columns:\n",
    "        f.writelines(\"\\n\" + col)\n",
    "        f.writelines(\"\\nMean= \" + str(data[col].mean()))\n",
    "        f.writelines(\"     Median= \" + str(data[col].median()))\n",
    "        f.writelines(\"     Mode= \" + str(mode) for mode in data[col].mode())\n",
    "    f.writelines(\"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# FUNCTION TO CALCULATE VALUE COUNTS OF CATEGORICAL COLUMNS \n",
    "def ValueCounts(f, data, target, columns):\n",
    "    # To view summary aggregates \n",
    "    f.writelines(\"\\n\\nVALUE COUNTS:\\n\\n\")\n",
    "    dataf= pd.DataFrame(list(zip(data[target].value_counts().index,data[target].value_counts())), columns=['Column','counts'])\n",
    "    f.write(tabulate(dataf, tablefmt=\"grid\", headers=\"keys\", showindex=False))\n",
    "    f.writelines(\"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    #return dt_string\n",
    "\n",
    "# FUNCTION TO CHECK EFFECT OF CATEGORICAL VARIABLES ON DATA SET \n",
    "def GroupBy(f, data, target, columns):\n",
    "    f.writelines(\"\\n\\nTO SEE EFFECT OF CATEGORICAL VARIABLES ON DATA SET\\n\\n\")\n",
    "    for i in columns:\n",
    "        dataf = pd.DataFrame(data.groupby([target,i]))\n",
    "        f.write(tabulate(dataf, tablefmt=\"grid\", headers=\"keys\", showindex=False))\n",
    "        f.writelines(\"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "#FUNCTION TO TEST NORMALITY OF THE DATASET\n",
    "def Normality(f, data, target, columns):    \n",
    "    # Normality Test\n",
    "    f.writelines(\"\\n\\nNormality Tests:\")\n",
    "    # Shapiro-Wilk test\n",
    "    ShapiroWilkTest(f, data, target, columns)\n",
    "    #D'Agostino's K^2 Test \n",
    "    Agostino(f, data, target, columns)\n",
    "    #Anderson-Darling Test\n",
    "    AndersonDarlingTest(f, data, target, columns)\n",
    "    \n",
    "def ShapiroWilkTest(f, data, target, columns):\n",
    "    f.writelines(\"\\nShapiro-Wilk test - Gaussian distribution test\\n\")\n",
    "    f.writelines(\"Tests whether a data sample has a Gaussian distribution.\\n\")\n",
    "    f.writelines(\"Hypothesis: the sample has a Gaussian distribution\\n\")\n",
    "    ls = []\n",
    "    for i in columns:\n",
    "        if i == target:\n",
    "            continue\n",
    "        stat, p = shapiro(data[i])\n",
    "        if p > 0.05:\n",
    "            result = \"Accepted\"\n",
    "        else:\n",
    "            result = \"Rejected\"\n",
    "        ls.append([i, stat, p, result])\n",
    "    dataf = pd.DataFrame(ls, columns=[\"Column\", \"Test Statistics\", \"p-Value\", \"Null Hypothesis\"])\n",
    "    f.write(tabulate(dataf, tablefmt=\"grid\", headers=\"keys\", showindex=False))\n",
    "    f.writelines(\n",
    "        \"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    \n",
    "def Agostino(f, data, target, columns):    \n",
    "    f.writelines(\"\\n\\nD'Agostino's K^2 Test - Gaussian distribution test\\n\")\n",
    "    f.writelines(\"Tests whether a data sample has a Gaussian distribution.\\n\")\n",
    "    f.writelines(\"Hypothesis: the sample has a Gaussian distribution\\n\")\n",
    "    ls = []\n",
    "    for i in columns:\n",
    "        if i == target:\n",
    "            continue\n",
    "        stat, p = normaltest(data[i])\n",
    "        if p > 0.05:\n",
    "            result = \"Accepted\"\n",
    "        else:\n",
    "            result = \"Rejected\"\n",
    "        ls.append([i, stat, p, result])\n",
    "    dataf = pd.DataFrame(ls, columns=[\"Column\", \"Test Statistics\", \"p-Value\", \"Null Hypothesis\"])\n",
    "    f.write(tabulate(dataf, tablefmt=\"grid\", headers=\"keys\", showindex=False))\n",
    "    f.writelines(\n",
    "        \"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "def AndersonDarlingTest(f, data, target, columns):\n",
    "    f.writelines(\"\\n\\nAnderson-Darling Test - Gaussian distribution test\\n\")\n",
    "    f.writelines(\"Tests whether a data sample has a Gaussian distribution.\\n\")\n",
    "    f.writelines(\"Hypothesis: the sample has a Gaussian distribution\\n\")\n",
    "    for i in columns:\n",
    "        if i == target:\n",
    "            continue\n",
    "        result = anderson(data[i])\n",
    "        f.writelines('\\n' + i + ':\\nStatistic: ' + str(result.statistic) + '\\n')\n",
    "        for j in range(len(result.critical_values)):\n",
    "            sl, cv = result.significance_level[j], result.critical_values[j]\n",
    "            if result.statistic < result.critical_values[j]:\n",
    "                f.writelines(str(sl) + ':' + str(cv) + ' Null Hypothesis - Accepted\\n')\n",
    "            else:\n",
    "                f.writelines(str(sl) + ':' + str(cv) + ' Null Hypothesis - Rejected\\n')\n",
    "\n",
    "    f.writelines(\n",
    "        \"\\n---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "def analysisInteraction(path,target):\n",
    "    f = open(\"Analysis.txt\", \"w\")\n",
    "    \n",
    "    data = pd.read_csv(path, sep=',', header=0)\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    analysis(f,data,target,columns)\n",
    "    f.close()\n",
    "    return \"Analysis.txt\"\n",
    "\n",
    "analysisInteraction(\"Crime1.csv\",\"Category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
